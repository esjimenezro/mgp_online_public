{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference Overview and Variable Elimination Algorithm\n",
    "\n",
    "<img style=\"float: right; margin: 0px 0px 15px 15px;\" src=\"https://static.thenounproject.com/png/542457-200.png\" width=\"300px\" height=\"300px\" />\n",
    "\n",
    "> So long, we have talked about probabilistic graphical model representation (PGM).\n",
    "> - We've seen that there are two main types: Bayesian networks (directed) and Markov networks (undirected).\n",
    "> - We've alse seen that they encode different **independence assumptions**.\n",
    ">\n",
    "> In this module, we will operationalize the PGMs and study how to use these representations (models) to answer actual queries or questions.\n",
    "\n",
    "> **Objetives:**\n",
    "> - To learn the different types of queries one can perform to a PGM.\n",
    "> - To describe the Variable Elimination algorithm.\n",
    "> - To analyze the computational complexity of the Variable Elimination algorithm.\n",
    "> - To learn how to use the Variable Elimination algorithm to answer a query to an actual network.\n",
    "\n",
    "> **References:**\n",
    "> - Probabilistic Graphical Models: Principles and Techniques, By Daphne Koller and Nir Friedman. Ch. 9.\n",
    "> - Mastering Probabilistic Graphical Models Using Python, By Ankur Ankan and Abinash Panda. Ch. 3.\n",
    "> - Probabilistic Graphical Models Specialization, offered through Coursera. Prof. Daphne Koller.\n",
    "\n",
    "\n",
    "<p style=\"text-align:right;\"> Imagen recuperada de: https://static.thenounproject.com/png/542457-200.png.</p>\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Inference - Overview\n",
    "\n",
    "In the previous module, we looked at the different types of representations and how to use them to create models for some problems.\n",
    "\n",
    "We also saw how the probabilities of variables change when we incorporate evidence, in an intuitive way.\n",
    "\n",
    "In this module, we will describe several algorithms to compute these probabilities and how they may change. Similarly, we will see how to use inference algorithms to predict the values of variables based on our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Conditional probability queries\n",
    "\n",
    "These are the most common queries. Given:\n",
    "\n",
    "- A joint probability distribution\n",
    "\n",
    "  $$P(X_1,\\dots, X_n),$$\n",
    "\n",
    "  (which is modeled through a BN or a MN);\n",
    "  \n",
    "- a set of query variables $\\bar{Y}\\subseteq \\left\\{X_1,\\dots, X_n\\right\\}$;\n",
    "\n",
    "- and a set of observed variables (evidence) $\\bar{E} = \\bar{e}$, con $\\bar{E}\\subseteq \\left\\{X_1,\\dots, X_n\\right\\}$,\n",
    "\n",
    "we define $\\bar{W} = \\left\\{X_1,\\dots, X_n\\right\\} \\setminus \\left\\{\\bar{Y} \\cup \\bar{E}\\right\\}$ as the rest of the variables.\n",
    "\n",
    "The task is to compute the *conditional probability query* $P(\\bar{Y} | \\bar{E}=\\bar{e})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Applications:**\n",
    "\n",
    "- In the credit-worthiness model of the exam, we saw that the bank was able to observe some variables. Then we would be interested in computing the probability of the unobserved variables given the evidence that the bank observes.\n",
    "\n",
    "- In a medical diagnosis system, we observe certain symptoms and some test results and we are interested in computing the probability of different diseases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By definition of conditional probability:\n",
    "\n",
    "$$P(\\bar{Y} | \\bar{E}=\\bar{e}) = \\frac{P(\\bar{Y}, \\bar{e})}{P(\\bar{e})}.$$\n",
    "\n",
    "In this expression:\n",
    "\n",
    "- $P(\\bar{Y}, \\bar{e}) = \\sum_{\\bar{W}} P(\\bar{Y}, \\bar{e}, \\bar{W})$.\n",
    "\n",
    "  Recall that $\\left\\{X_1,\\dots, X_n\\right\\} = \\bar{Y} \\cup \\bar{E} \\cup \\bar{W}$. Then, the terms in the right-side sumation are joint probabilities of all the variables.\n",
    "  \n",
    "- $P(\\bar{e}) = \\sum_{\\bar{Y}} P(\\bar{Y}, \\bar{e})$.\n",
    "\n",
    "  This is simply a normalizing constant for converting $P(\\bar{Y}, \\bar{e})$ into $P(\\bar{Y} | \\bar{e})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, in principle, we could:\n",
    "\n",
    "- Take a PGM;\n",
    "- multiply all of its factors to obtain the joint distribution;\n",
    "- sum out (marginalize) the unwanted variables in the joint distribution;\n",
    "- and, that's it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Examples:**\n",
    "\n",
    "1. Bayesian networks: restaurant example.\n",
    "\n",
    "   Random variables:\n",
    "   - Location $L$ (Bad: $l^0$, Good: $l^1$).\n",
    "   - Quality $Q$ (Bad: $q^0$, Normal: $q^1$, Good: $q^2$).\n",
    "   - Cost $C$ (Low: $c^0$, High: $c^1$).\n",
    "   - Number of people $N$ (Low: $n^0$, High: $n^1$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(\"figures/restaurant.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will forget about if factors represent CPDs or general affinity functions.\n",
    "\n",
    "In this case:\n",
    "\n",
    "$$P(L,Q,C,N)= \\phi_L(L)\\phi_Q(Q)\\phi_C(C,L,Q)\\phi_N(N,L,C).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'd like, for example:\n",
    "\n",
    "$$P(N)=\\sum_{L,Q,C}\\phi_L(L)\\phi_Q(Q)\\phi_C(C,L,Q)\\phi_N(N,L,C).$$\n",
    "\n",
    "> Sum-product algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pgmpy.factors.discrete.DiscreteFactor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define factors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joint probability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P(N)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Markov networks: pairwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(\"figures/pairwiseMN.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example\n",
    "\n",
    "$$P(D) = \\frac{1}{Z}\\sum_{A,B,C}\\phi_1(A,B)\\phi_2(B,C)\\phi_3(C,D)\\phi_4(A,D).$$\n",
    "\n",
    "> Sum-product algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**So, what is the problem?**\n",
    "\n",
    "*There is an exponential blow-up of the joint distribution that the graphical model representation was precisely designed to avoid*.\n",
    "\n",
    "In fact, the problem of inference in PGMs (just like most interesting problems) is $\\mathcal{NP}-$hard. *What does this mean?*\n",
    "\n",
    "- If a problem is $\\mathcal{NP}-$hard it is very unlikely to come up with an efficient solution (in the general case).\n",
    "\n",
    "- This means that **all the algorithms** that people have constructed to solve this problem require a time (or number of operations) which is at leat exponential in the size of the representation of the problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we will be seeing a variety of algorithms for both, exact and approximate inference that can do considerably better that this worst case result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Maximum A-Posteriori (MAP) Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given:\n",
    "\n",
    "- A joint probability distribution\n",
    "\n",
    "  $$P(X_1,\\dots, X_n),$$\n",
    "\n",
    "  (which is modeled through a BN or a MN);\n",
    "  \n",
    "- a set of query variables $\\bar{Y}\\subseteq \\left\\{X_1,\\dots, X_n\\right\\}$;\n",
    "\n",
    "- and a set of observed variables (evidence) $\\bar{E} = \\bar{e}$, con $\\bar{E}\\subseteq \\left\\{X_1,\\dots, X_n\\right\\}$.\n",
    "\n",
    "In this case, we assume for simplicity that $\\bar{Y}\\cup \\bar{E} = \\left\\{X_1,\\dots, X_n\\right\\}$.\n",
    "\n",
    "The task is to compute \n",
    "\n",
    "$$MAP(\\bar{Y} | \\bar{E}=\\bar{e}) = \\arg\\max_{\\bar{y}\\in\\mathrm{Val}(\\bar{Y})} P(\\bar{Y} | \\bar{E}=\\bar{e}).$$\n",
    "\n",
    "> There may be multiple solutions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Application:**\n",
    "\n",
    "- Classifier: Once we learn a model from data, we would like to compute the most likely assignment for a set of variables given some observed variables (evidence)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MAP $\\neq$ Max over marginals:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(\"figures/simple.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, this problem is $\\mathcal{NP}-$hard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 2. Variable Elimination\n",
    "\n",
    "This is the simplest and most fundamental algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Initial examples\n",
    "\n",
    "We will introduce the **variable elimination (VE) algorithm** through a number of simple examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Elimination in a chain**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the following pairwise chain MN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(\"figures/MNchain.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have that:\n",
    "\n",
    "$$P(A,B,C,D,E) \\propto \\phi_1(A,B)\\phi_2(B,C)\\phi_3(C,D)\\phi_4(D,E)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our objective is to calculate $P(E)$ (<font color=blue>in the whiteboard, then show</font>):\n",
    "\n",
    "$$\\begin{align}P(E) \\propto & %\\sum_{D,C,B,A} \\phi_1(A,B)\\phi_2(B,C)\\phi_3(C,D)\\phi_4(D,E) \\\\\n",
    "                          %= & \\sum_{D}\\sum_{C}\\sum_{B}\\sum_{A} \\phi_1(A,B)\\phi_2(B,C)\\phi_3(C,D)\\phi_4(D,E) \\\\\n",
    "                          %= & \\sum_{D}\\sum_{C}\\sum_{B} \\phi_2(B,C)\\phi_3(C,D)\\phi_4(D,E) \\underbrace{\\sum_{A} \\phi_1(A,B)}_{\\tau_1(B)} \\\\\n",
    "                          %= & \\sum_{D}\\sum_{C}\\sum_{B} \\phi_2(B,C)\\phi_3(C,D)\\phi_4(D,E) \\tau_1(B) \\\\\n",
    "                          %= & \\sum_{D}\\sum_{C} \\phi_3(C,D)\\phi_4(D,E) \\underbrace{\\sum_{B} \\phi_2(B,C)\\tau_1(B)}_{\\tau_2(C)} \\\\\n",
    "                          %= & \\sum_{D}\\phi_4(D,E) \\underbrace{\\sum_{C} \\phi_3(C,D)\\tau_2(C)}_{\\tau_3(D)} \\\\\n",
    "                          %= & \\sum_{D}\\phi_4(D,E)\\tau_3(D) = \\tau_4(E)\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Elimination in a BN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(\"figures/restaurant.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The joint probability is:\n",
    "\n",
    "$$P(L,Q,C,N)= \\phi_L(L)\\phi_Q(Q)\\phi_C(C,L,Q)\\phi_N(N,L,C).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to calculate $P(N)$ (<font color=blue>in the whiteboard, then show</font>):\n",
    "\n",
    "$$\\begin{align} P(N) = & %\\sum_{L,C,Q}\\phi_L(L)\\phi_Q(Q)\\phi_C(C,L,Q)\\phi_N(N,L,C) \\\\\n",
    "                    %= & \\sum_{L}\\sum_{C}\\sum_{Q} \\phi_L(L)\\phi_Q(Q)\\phi_C(C,L,Q)\\phi_N(N,L,C) \\\\\n",
    "                    %= & \\sum_{L}\\sum_{C} \\phi_L(L)\\phi_N(N,L,C) \\underbrace{\\sum_{Q} \\phi_Q(Q) \\phi_C(C,L,Q)}_{\\tau_1(C,L)} \\\\\n",
    "                    %= & \\sum_{L} \\phi_L(L) \\underbrace{\\sum_{C}\\phi_N(N,L,C)\\tau_1(C,L)}_{\\tau_2(N,L)} \\\\\n",
    "                    %= & \\sum_{L} \\phi_L(L)\\tau_2(N,L) = \\tau_3(N)\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pgmpy.models.BayesianModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pgmpy.factors.discrete.TabularCPD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model skeleton\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CPDs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attach CPDs to the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the model is correctly defined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pgmpy.inference.VariableElimination\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create inference object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What happens if we have evidence?**\n",
    "\n",
    "If we now want to calculate $P(N, L=l^1)$:\n",
    "\n",
    "- First, we should reduce our factors according to the given evidence: $\\phi_L(l^1)=\\phi_L'()$, $\\phi_C(C,l^1,Q)=\\phi_C'(C,Q)$, $\\phi_N(N,l^1,C)=\\phi_N'(N,C)$.\n",
    "- Then, we run the VE algorithm as usual:\n",
    "\n",
    "$$\\begin{align} P(N, l^1) = & \\sum_{C,Q}\\phi_L'()\\phi_Q(Q)\\phi_C'(C,Q)\\phi_N'(N,C) \\\\\n",
    "                         = & \\sum_{C}\\sum_{Q} \\phi_L'()\\phi_Q(Q)\\phi_C'(C,Q)\\phi_N'(N,C) \\\\\n",
    "                         = & \\sum_{C} \\phi_L'()\\phi_N'(N,C) \\underbrace{\\sum_{Q} \\phi_Q(Q) \\phi_C'(C,Q)}_{\\tau_1(C)} \\\\\n",
    "                         = & \\sum_{C} \\phi_L'()\\phi_N'(N,C) \\tau_1(C)\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**And, if we want the conditional probability?**\n",
    "\n",
    "You only have to take the above and renormalize:\n",
    "\n",
    "$$P(N|l^1)=\\frac{P(N,l^1)}{P(l^1)}.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Perform query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Algorithm description and computational complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Algorithm description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the algorithm description, we have a set of factors $\\bar{\\Phi}$.\n",
    "\n",
    "In the examples above:\n",
    "\n",
    "1. MN: $\\bar{\\Phi}=\\{\\phi_1(A,B), \\phi_2(B,C), \\phi_3(C,D), \\phi_4(D,E)\\}$.\n",
    "2. BN: $\\bar{\\Phi}=\\{\\phi_L(L), \\phi_Q(Q), \\phi_C(C,L,Q), \\phi_N(N,L,C)\\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will describe the steps for eliminating some variable $Z$ from $\\bar{\\Phi}$: *Eliminate Var-$Z$ from $\\bar{\\Phi}$*.\n",
    "\n",
    "1. Determine the set of factors that involve $Z$:\n",
    "\n",
    "   $$\\Phi' = \\left\\{\\phi_i \\in \\Phi : Z  \\in \\mathrm{scope}[\\phi_i]\\right\\}$$\n",
    "\n",
    "2. Compute:\n",
    "\n",
    "   $$\\psi = \\prod_{\\phi_i \\in \\Phi'} \\phi_i$$\n",
    "   \n",
    "3. Compute:\n",
    "\n",
    "   $$\\tau = \\sum_Z \\psi$$\n",
    "   \n",
    "4. Overwrite:\n",
    "   \n",
    "   $$\\bar{\\Phi} := \\left(\\bar{\\Phi}\\setminus \\Phi'\\right) \\cup \\{\\tau\\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, the complete algorithm can be described as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The first step is to reduce all factors in $\\bar{\\Phi}$ acording to the given evidence, if any."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. For each non-query variable $Z$:\n",
    "   - Eliminate Var-$Z$ from $\\bar{\\Phi}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Multiply all the remaining factors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computational complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We analyze the computational complexity of Eliminate Var-$Z$ from $\\bar{\\Phi}$.\n",
    "\n",
    "1. Determine the set of factors that involve $Z$:\n",
    "\n",
    "   $$\\Phi' = \\left\\{\\phi_i \\in \\Phi : Z  \\in \\mathrm{scope}[\\phi_i]\\right\\}$$\n",
    "\n",
    "2. Compute:\n",
    "\n",
    "   $$\\psi = \\prod_{\\phi_i \\in \\Phi'} \\phi_i$$\n",
    "   \n",
    "3. Compute:\n",
    "\n",
    "   $$\\tau = \\sum_Z \\psi$$\n",
    "   \n",
    "4. Overwrite:\n",
    "   \n",
    "   $$\\Phi := \\left(\\Phi\\setminus \\Phi'\\right) \\cup \\{\\tau\\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Complexity of the second step:** Assume that $|\\Phi'| = m_k$ (the number of factors that involve $Z$ is $m_k$). Thus,\n",
    "\n",
    "   $$\\psi(\\bar{X}_k) = \\prod_{i=1}^{m_k} \\phi_i.$$\n",
    "   \n",
    "   Now, assuming that $N_k = |\\mathrm{Val}(\\bar{X}_k)|$ (the number of rows in the factor resulting from the multiplication), the computational cost of this step is:\n",
    "   \n",
    "   $$N_k (m_k - 1)$$\n",
    "   \n",
    "   (each row in the resulting factor is produced by $m_k - 1$ multiplications). <font color=blue>See this in the whiteboard</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Complexity of the third step:** \n",
    "\n",
    "   $$\\tau_k (\\bar{X}_k \\setminus \\{Z\\}) = \\sum_Z \\phi(\\bar{X}_k)$$\n",
    "   \n",
    "   Assuming that $|\\mathrm{Val}(Z)|=z$ (the number of possible values of the variable $Z$). The computational cost of this step is (Each row of the resulting factor involves $z-1$ sumations):\n",
    "   \n",
    "   $$N_k \\frac{(z-1)}{z} \\leq N_k.$$\n",
    "   \n",
    "   <font color=blue>See this in the whiteboard</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The whole algorithm:**\n",
    "\n",
    "1. At most, $n$ elimination steps ($n$ is the number of variables).\n",
    "\n",
    "2. Start with $m = |\\bar{\\Phi}|$ factors. \n",
    "\n",
    "3. At each elimination step, generate $1$ factor ($\\psi$).\n",
    "\n",
    "4. Total number of factors is $m^{\\ast}\\leq m+n$.\n",
    "\n",
    "5. $N:=\\max_k N_k$: size of the biggest factor.\n",
    "\n",
    "6. Number of product operations (each factor is multiplied only once):\n",
    "   \n",
    "   $$\\sum_k N_k(m_k-1)\\leq N m^{\\ast}.$$\n",
    "   \n",
    "7. Operaciones marginalización (cada factor se multiplica a lo sumo una vez):\n",
    "\n",
    "   $$\\sum_k N_k\\leq N n.$$\n",
    "   \n",
    "> Until here, the computational cost is linear in $N$ and in $m^\\ast$.\n",
    "\n",
    "8. However, $N_k=|\\mathrm{Val}(\\bar{X}_k)|=\\mathcal{O}(d^{r_k})$, where\n",
    "  - $d:=\\max |\\mathrm{Val}(X_i)|$;\n",
    "  - $r_k=|\\bar{X}_k|$.\n",
    "  \n",
    "> Exponential blowup!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In the BN example**\n",
    "\n",
    "- Operation: $\\tau_1(C,L)=\\sum_{Q}\\phi_Q(Q)\\phi_C(C,L,Q)$ - $r_1=3$.\n",
    "\n",
    "- Operation: $\\tau_2(N,L)=\\sum_{C}\\phi_N(N,L,C)\\tau_1(C,L)$ - $r_2=3$.\n",
    "\n",
    "- Operation: $\\tau_3(N)=\\sum_{L}\\phi_L(L)\\tau_2(N,L)$ - $r_3=2$.\n",
    "\n",
    "On the other hand $d=3$. Total computational complexity $\\leq (n+m^\\ast) d^{r_k}=(4+7) 3^3 = 297$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform query with given elimination order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A different elimination order**\n",
    "\n",
    "$$\\begin{align} P(N) = & \\sum_{L,C,Q}\\phi_L(L)\\phi_Q(Q)\\phi_C(C,L,Q)\\phi_N(N,L,C) \\\\\n",
    "                     = & \\sum_{L}\\sum_{C}\\sum_{Q} \\phi_L(L)\\phi_Q(Q)\\phi_C(C,L,Q)\\phi_N(N,L,C) \\\\\n",
    "                     = & \\sum_{Q}\\sum_{C} \\phi_Q(Q) \\underbrace{\\sum_{L} \\phi_L(L) \\phi_C(C,L,Q) \\phi_N(N,L,C)}_{\\tau_1(Q,C,N)} \\\\\n",
    "                     = & \\sum_{Q} \\phi_Q(Q) \\underbrace{\\sum_{C} \\tau_1(Q,C,N)}_{\\tau_2(Q,N)} \\\\\n",
    "                     = & \\sum_{Q} \\phi_Q(Q)\\tau_2(Q,N)\n",
    "\\end{align}$$\n",
    "\n",
    "- Operation: $\\tau_1(Q,C,N) = \\sum_{L} \\phi_L(L) \\phi_C(C,L,Q) \\phi_N(N,L,C)$ - $r_1=4$\n",
    "\n",
    "- Operation: $\\tau_2(Q,N) = \\sum_{C} \\tau_1(Q,C,N)$ - $r_2=3$\n",
    "\n",
    "- Operation: $\\tau_3(Q) = \\sum_{Q} \\phi_Q(Q)\\tau_2(Q,N)$ - $r_3=2$ \n",
    "\n",
    "On the other hand $d=3$. Total computational complexity $\\leq (n+m^\\ast) d^{r_k}=(4+7) 3^4 = 891$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform query with given elimination order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compare execution times using timeit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The computational complexity strongly depends on the elimination order!\n",
    "\n",
    "The result is the same for any elimination order though."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Finding elimination orderings\n",
    "\n",
    "The VE algorithm works well no matter the selected ordering. However, we have shown that the ordering significantly affects the computation complexity of the algorithm.\n",
    "\n",
    "**How do we find a good elimination ordering?**\n",
    "\n",
    "- Good ideas can be obtained from the graphical representation. We won't cover that here, but you can take a look at Section 9.4, pages 305-315."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, one often performs **greedy search using heuristic cost functions** (at each iteration calculate the variable to eliminate to obtain the smallest cost).\n",
    "\n",
    "> These algorithms are not optimal, but perform sufficiently well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible cost functions:\n",
    "\n",
    "- min-weight: # of values of factor formed ($N_k$).\n",
    "- min-neighbors: # of resulting neighbor nodes after variable elimination.\n",
    "- min-fill: # of new fill edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min-weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min-neighbors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min-fill (default)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare execution times using timeit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Announcements\n",
    "\n",
    "## 1. Quiz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<script>\n",
    "  $(document).ready(function(){\n",
    "    $('div.prompt').hide();\n",
    "    $('div.back-to-top').hide();\n",
    "    $('nav#menubar').hide();\n",
    "    $('.breadcrumb').hide();\n",
    "    $('.hidden-print').hide();\n",
    "  });\n",
    "</script>\n",
    "\n",
    "<footer id=\"attribution\" style=\"float:right; color:#808080; background:#fff;\">\n",
    "Created with Jupyter by Esteban Jiménez Rodríguez.\n",
    "</footer>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
